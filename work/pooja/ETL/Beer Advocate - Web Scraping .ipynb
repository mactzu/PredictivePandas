{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping beer review site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies for data wrangling  \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies for scraping\n",
    "import pymongo\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#from splinter import Browser \n",
    "#from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Open the Chrome Driver Browser\n",
    "#executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "#browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in CSV\n",
    "beer_df = pd.read_csv(\"../../Data/beer.gz\", encoding=\"ISO-8859-1\")\n",
    "beer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations \n",
    "1. Dropping unecessary columns \n",
    "2. Reset the index \n",
    "3. Set the brewery_id as the new index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"unnamed: 0\" column \n",
    "beer_df = beer_df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# Drop duplicates in the \"brewery_id\" column\n",
    "beer_df.drop_duplicates(subset = \"brewery_id\", keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the brewery_id as index \n",
    "# beer_df = beer_df.set_index(\"brewery_id\")\n",
    "beer_df = beer_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for scraping \n",
    "\n",
    "(As shown in the images below) The HTML format of the addresses in each profile page is messy, each text is not placed in a div making it hard to access the different elements of an address using beautiful soup. A function needs to be created to separate the Postal Code from the Country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of countries that have breweries in our dataset\n",
    "countries = [\"Belgium\", \"Czech Republic\", \"Germany\", \"Denmark\", \"France\", \"United Kingdom\", \"Netherlands\", \"Sweden\",\n",
    "             \"United States\", \"Russia\", \"Japan\", \"Italy\"]\n",
    "\n",
    "# Create a function that formats the address - splitting the postal code from the country  \n",
    "def formatAddress(address):\n",
    "    for country in countries:\n",
    "        if country in address:\n",
    "            return address.split(country)[0] + \" \" + country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty column in our dataframe for the address \n",
    "beer_df[\"address\"] = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the iterrows() function to iterate over beer_df\n",
    "for index, row in beer_df.iterrows():\n",
    "    \n",
    "    if row[\"address\"] == \"\": \n",
    "        \n",
    "        # URL of page to be scraped\n",
    "        url = \"https://www.beeradvocate.com/beer/profile/\" + str(row['brewery_id']) + \"/\"\n",
    "        \n",
    "        # retrieve page with the requests module\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Create a bs object and parse with html \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Examine the results \n",
    "        results = soup.find_all('div', {\"id\": \"info_box\"})\n",
    "        \n",
    "        # Loop through returned results and clean up the html text\n",
    "        for r in results:\n",
    "            text_break = r.text.split(\"\\n\") \n",
    "            \n",
    "            for line in text_break:   \n",
    "                if \"map\" in line: \n",
    "                    \n",
    "                    # Error handling \n",
    "                    try:\n",
    "                        beer_df.loc[index, \"address\"] = formatAddress(line)\n",
    "                        print(beer_df.loc[index, \"address\"])\n",
    "                        \n",
    "                    except:\n",
    "                        print(f'no address for {row[\"brewery_id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brewery_ids = beer_df[\"brewery_id\"].unique()\n",
    "type(brewery_ids)\n",
    "len(brewery_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "address_list = list()\n",
    "count = 0\n",
    "\n",
    "for brewery_id in brewery_ids_2:\n",
    "    \n",
    "        url = \"https://www.beeradvocate.com/beer/profile/\" + str(brewery_id) + \"/\"\n",
    "        browser.visit(url)\n",
    "        sleep(1)\n",
    "\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "        \n",
    "        try:\n",
    "\n",
    "            browser.links.find_by_partial_text('map').click()\n",
    "            browser.windows[1].is_current = True\n",
    "            sleep(1)\n",
    "\n",
    "            html = browser.html \n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            input_tag = soup.find(id = \"searchboxinput\")\n",
    "            output = input_tag['value']\n",
    "\n",
    "            address_list.append({\n",
    "                \"brewery_id\": brewery_id,\n",
    "                \"address\": output\n",
    "            })\n",
    "\n",
    "            count += 1\n",
    "            print(count)\n",
    "            \n",
    "            browser.windows[1].close()\n",
    "\n",
    "        except:\n",
    "            pass \n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df = pd.DataFrame(list(address_list), columns = ['brewery_id', 'address'])\n",
    "address_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the census data to csv to load to database\n",
    "address_df.to_csv('second_set_address.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
